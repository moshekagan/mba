{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n",
      "customerID             0\n",
      "gender                 0\n",
      "SeniorCitizen          0\n",
      "Partner                0\n",
      "Dependents             0\n",
      "tenure                 0\n",
      "PhoneService           0\n",
      "MultipleLines          0\n",
      "InternetService        0\n",
      "OnlineSecurity         0\n",
      "OnlineBackup           0\n",
      "DeviceProtection       0\n",
      "TechSupport            0\n",
      "StreamingTV            0\n",
      "StreamingMovies        0\n",
      "Contract               0\n",
      "PaperlessBilling       0\n",
      "PaymentMethod          0\n",
      "MonthlyCharges         0\n",
      "TotalCharges           0\n",
      "Churn               2045\n",
      "dtype: int64\n",
      "ğŸ“Š The model predicted 436 out of 2045 customers will churn.\n",
      "âœ… F1 Score on validation set: 0.5826\n"
     ]
    }
   ],
   "source": [
    "# Churn Prediction - Final Pipeline with Logistic Regression\n",
    "import pandas as pd\n",
    "\n",
    "# ×˜×•×¢×Ÿ ××ª ×”×§×‘×¦×™×\n",
    "training_df = pd.read_csv(\"churn_training.csv\")\n",
    "holdout_df = pd.read_csv(\"churn_holdout.csv\")\n",
    "\n",
    "# ×”××¨×ª ×”×¢××•×“×” TotalCharges ×œ××¡×¤×¨×™×, ×©×’×™××•×ª ×™×”×¤×›×• ×œ-NaN\n",
    "training_df['TotalCharges'] = pd.to_numeric(training_df['TotalCharges'], errors='coerce')\n",
    "holdout_df['TotalCharges'] = pd.to_numeric(holdout_df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# ××™×œ×•×™ ×¢×¨×›×™× ×—×¡×¨×™× ×‘×¢××•×“×•×ª ××¡×¤×¨×™×•×ª ×‘×¢×–×¨×ª ×”×—×¦×™×•× ×™\n",
    "for col in ['MonthlyCharges', 'TotalCharges', 'tenure', 'SeniorCitizen']:\n",
    "    training_df[col].fillna(training_df[col].median(), inplace=True)\n",
    "    holdout_df[col].fillna(holdout_df[col].median(), inplace=True)\n",
    "\n",
    "# ××™×œ×•×™ ×¢×¨×›×™× ×—×¡×¨×™× ×‘×¢××•×“×•×ª ×§×˜×’×•×¨×™××œ×™×•×ª ×‘×¢×–×¨×ª ×”×¢×¨×š ×”×©×›×™×—\n",
    "categorical_cols = ['Partner', 'Dependents', 'InternetService', 'DeviceProtection',\n",
    "                    'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "for col in categorical_cols:\n",
    "    training_df[col].fillna(training_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# ×‘×“×™×§×”: ×”×× × ×•×ª×¨×• ×¢×¨×›×™× ×—×¡×¨×™×?\n",
    "print(training_df.isnull().sum())\n",
    "print(holdout_df.isnull().sum())\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ××©×ª× ×™× ××¡×‘×™×¨×™× ×•×ª×œ×•×™×™×\n",
    "X = training_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "y = training_df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})  # ×”××¨×” ×œ×¢×¨×›×™× ×‘×™× ××¨×™×™×\n",
    "\n",
    "X_holdout = holdout_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "\n",
    "# ×¤×™×¦×•×œ ×œÖ¾Train / Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ××©×ª× ×™× ×§×˜×’×•×¨×™××œ×™×™× ×•×›××•×ª×™×™×\n",
    "categorical_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "# Pipeline ×œ×¢×™×‘×•×“ ×§×˜×’×•×¨×™××œ×™\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Pipeline ×œ×¢×™×‘×•×“ ×›××•×ª×™\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# ×××—×“ ××ª ×”×›×œ\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    (\"num\", numeric_pipeline, numeric_cols)\n",
    "])\n",
    "# ××ª××™× ××ª ×”-preprocessing ×¢×œ ×¡×˜ ×”××™××•×Ÿ ×•××™×™×©× ×’× ×¢×œ ×¡×˜ ×”××™××•×ª\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_holdout_processed = preprocessor.transform(X_holdout)\n",
    "# Step 1: Re-import required packages\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 2: Load and clean the data\n",
    "training_df = pd.read_csv(\"churn_training.csv\")\n",
    "holdout_df = pd.read_csv(\"churn_holdout.csv\")\n",
    "\n",
    "# Convert 'TotalCharges' to numeric, coerce errors\n",
    "training_df['TotalCharges'] = pd.to_numeric(training_df['TotalCharges'], errors='coerce')\n",
    "holdout_df['TotalCharges'] = pd.to_numeric(holdout_df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "for col in ['MonthlyCharges', 'TotalCharges', 'tenure', 'SeniorCitizen']:\n",
    "    training_df[col].fillna(training_df[col].median(), inplace=True)\n",
    "    holdout_df[col].fillna(holdout_df[col].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical values with most frequent\n",
    "categorical_cols_fill = ['Partner', 'Dependents', 'InternetService', 'DeviceProtection',\n",
    "                         'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "for col in categorical_cols_fill:\n",
    "    training_df[col].fillna(training_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Step 3: Feature/Target separation and split for evaluation\n",
    "X = training_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "y = training_df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X_holdout = holdout_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 4: Preprocessing pipeline\n",
    "categorical_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    (\"num\", numeric_pipeline, numeric_cols)\n",
    "])\n",
    "\n",
    "# Step 5: Train model on full data and generate predictions\n",
    "X_full = training_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "y_full = training_df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "X_full_processed = preprocessor.fit_transform(X_full)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_holdout_processed = preprocessor.transform(X_holdout)\n",
    "\n",
    "final_model = LogisticRegression(max_iter=1000)\n",
    "final_model.fit(X_full_processed, y_full)\n",
    "\n",
    "# Step 6: Make predictions and export CSV\n",
    "holdout_preds = final_model.predict(X_holdout_processed)\n",
    "submission = pd.DataFrame({\n",
    "    \"CustomerID\": holdout_df[\"customerID\"],\n",
    "    \"Prediction_Churn\": holdout_preds\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# Step 7: Evaluation on validation set\n",
    "val_preds = final_model.predict(X_val_processed)\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "\n",
    "print(f\"ğŸ“Š The model predicted {submission['Prediction_Churn'].sum()} out of {len(submission)} customers will churn.\")\n",
    "print(f\"âœ… F1 Score on validation set: {val_f1:.4f}\")\n",
    "\n",
    "# Explanation of F1:\n",
    "# F1 = 2 * (precision * recall) / (precision + recall)\n",
    "# It balances false positives and false negatives â€” good for imbalanced classes.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-29T21:10:13.549693Z",
     "start_time": "2025-07-29T21:10:13.044744Z"
    }
   },
   "id": "10fde19483b879c7",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c4ab5f1ca6b03f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
