{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n",
      "customerID             0\n",
      "gender                 0\n",
      "SeniorCitizen          0\n",
      "Partner                0\n",
      "Dependents             0\n",
      "tenure                 0\n",
      "PhoneService           0\n",
      "MultipleLines          0\n",
      "InternetService        0\n",
      "OnlineSecurity         0\n",
      "OnlineBackup           0\n",
      "DeviceProtection       0\n",
      "TechSupport            0\n",
      "StreamingTV            0\n",
      "StreamingMovies        0\n",
      "Contract               0\n",
      "PaperlessBilling       0\n",
      "PaymentMethod          0\n",
      "MonthlyCharges         0\n",
      "TotalCharges           0\n",
      "Churn               2045\n",
      "dtype: int64\n",
      "📊 The model predicted 436 out of 2045 customers will churn.\n",
      "✅ F1 Score on validation set: 0.5826\n"
     ]
    }
   ],
   "source": [
    "# Churn Prediction - Final Pipeline with Logistic Regression\n",
    "import pandas as pd\n",
    "\n",
    "# טוען את הקבצים\n",
    "training_df = pd.read_csv(\"churn_training.csv\")\n",
    "holdout_df = pd.read_csv(\"churn_holdout.csv\")\n",
    "\n",
    "# המרת העמודה TotalCharges למספרים, שגיאות יהפכו ל-NaN\n",
    "training_df['TotalCharges'] = pd.to_numeric(training_df['TotalCharges'], errors='coerce')\n",
    "holdout_df['TotalCharges'] = pd.to_numeric(holdout_df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# מילוי ערכים חסרים בעמודות מספריות בעזרת החציוני\n",
    "for col in ['MonthlyCharges', 'TotalCharges', 'tenure', 'SeniorCitizen']:\n",
    "    training_df[col].fillna(training_df[col].median(), inplace=True)\n",
    "    holdout_df[col].fillna(holdout_df[col].median(), inplace=True)\n",
    "\n",
    "# מילוי ערכים חסרים בעמודות קטגוריאליות בעזרת הערך השכיח\n",
    "categorical_cols = ['Partner', 'Dependents', 'InternetService', 'DeviceProtection',\n",
    "                    'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "for col in categorical_cols:\n",
    "    training_df[col].fillna(training_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# בדיקה: האם נותרו ערכים חסרים?\n",
    "print(training_df.isnull().sum())\n",
    "print(holdout_df.isnull().sum())\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# משתנים מסבירים ותלויים\n",
    "X = training_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "y = training_df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})  # המרה לערכים בינאריים\n",
    "\n",
    "X_holdout = holdout_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "\n",
    "# פיצול ל־Train / Validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# משתנים קטגוריאליים וכמותיים\n",
    "categorical_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "# Pipeline לעיבוד קטגוריאלי\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Pipeline לעיבוד כמותי\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# מאחד את הכל\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    (\"num\", numeric_pipeline, numeric_cols)\n",
    "])\n",
    "# מתאים את ה-preprocessing על סט האימון ומיישם גם על סט האימות\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_holdout_processed = preprocessor.transform(X_holdout)\n",
    "# Step 1: Re-import required packages\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Step 2: Load and clean the data\n",
    "training_df = pd.read_csv(\"churn_training.csv\")\n",
    "holdout_df = pd.read_csv(\"churn_holdout.csv\")\n",
    "\n",
    "# Convert 'TotalCharges' to numeric, coerce errors\n",
    "training_df['TotalCharges'] = pd.to_numeric(training_df['TotalCharges'], errors='coerce')\n",
    "holdout_df['TotalCharges'] = pd.to_numeric(holdout_df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "for col in ['MonthlyCharges', 'TotalCharges', 'tenure', 'SeniorCitizen']:\n",
    "    training_df[col].fillna(training_df[col].median(), inplace=True)\n",
    "    holdout_df[col].fillna(holdout_df[col].median(), inplace=True)\n",
    "\n",
    "# Fill missing categorical values with most frequent\n",
    "categorical_cols_fill = ['Partner', 'Dependents', 'InternetService', 'DeviceProtection',\n",
    "                         'StreamingMovies', 'Contract', 'PaymentMethod']\n",
    "for col in categorical_cols_fill:\n",
    "    training_df[col].fillna(training_df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Step 3: Feature/Target separation and split for evaluation\n",
    "X = training_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "y = training_df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "X_holdout = holdout_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 4: Preprocessing pipeline\n",
    "categorical_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "numeric_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns.tolist()\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cat\", categorical_pipeline, categorical_cols),\n",
    "    (\"num\", numeric_pipeline, numeric_cols)\n",
    "])\n",
    "\n",
    "# Step 5: Train model on full data and generate predictions\n",
    "X_full = training_df.drop(columns=[\"customerID\", \"Churn\"])\n",
    "y_full = training_df[\"Churn\"].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "X_full_processed = preprocessor.fit_transform(X_full)\n",
    "X_val_processed = preprocessor.transform(X_val)\n",
    "X_holdout_processed = preprocessor.transform(X_holdout)\n",
    "\n",
    "final_model = LogisticRegression(max_iter=1000)\n",
    "final_model.fit(X_full_processed, y_full)\n",
    "\n",
    "# Step 6: Make predictions and export CSV\n",
    "holdout_preds = final_model.predict(X_holdout_processed)\n",
    "submission = pd.DataFrame({\n",
    "    \"CustomerID\": holdout_df[\"customerID\"],\n",
    "    \"Prediction_Churn\": holdout_preds\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# Step 7: Evaluation on validation set\n",
    "val_preds = final_model.predict(X_val_processed)\n",
    "val_f1 = f1_score(y_val, val_preds)\n",
    "\n",
    "print(f\"📊 The model predicted {submission['Prediction_Churn'].sum()} out of {len(submission)} customers will churn.\")\n",
    "print(f\"✅ F1 Score on validation set: {val_f1:.4f}\")\n",
    "\n",
    "# Explanation of F1:\n",
    "# F1 = 2 * (precision * recall) / (precision + recall)\n",
    "# It balances false positives and false negatives — good for imbalanced classes.\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-07-29T21:10:13.549693Z",
     "start_time": "2025-07-29T21:10:13.044744Z"
    }
   },
   "id": "10fde19483b879c7",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8c4ab5f1ca6b03f6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
